{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados e bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs: caminho das pastas seguindo ambiente kaggle do desafio escolhido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-01T13:41:06.451826Z",
     "iopub.status.busy": "2025-04-01T13:41:06.451309Z",
     "iopub.status.idle": "2025-04-01T13:41:06.456930Z",
     "shell.execute_reply": "2025-04-01T13:41:06.455889Z",
     "shell.execute_reply.started": "2025-04-01T13:41:06.451762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.applications import EfficientNetB0\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:41:06.458595Z",
     "iopub.status.busy": "2025-04-01T13:41:06.458242Z",
     "iopub.status.idle": "2025-04-01T13:41:06.603115Z",
     "shell.execute_reply": "2025-04-01T13:41:06.601970Z",
     "shell.execute_reply.started": "2025-04-01T13:41:06.458562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:41:06.689533Z",
     "iopub.status.busy": "2025-04-01T13:41:06.689180Z",
     "iopub.status.idle": "2025-04-01T13:41:06.739256Z",
     "shell.execute_reply": "2025-04-01T13:41:06.738011Z",
     "shell.execute_reply.started": "2025-04-01T13:41:06.689492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# grupos do mesmo produto para análise de desempenho no treinamento\n",
    "tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "train['target'] = train.label_group.map(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:41:06.740697Z",
     "iopub.status.busy": "2025-04-01T13:41:06.740353Z",
     "iopub.status.idle": "2025-04-01T13:41:06.745871Z",
     "shell.execute_reply": "2025-04-01T13:41:06.744582Z",
     "shell.execute_reply.started": "2025-04-01T13:41:06.740657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def quant_batch(df, batch):\n",
    "    ct = len(df) // batch\n",
    "    ct += int(( (len(df)) % batch)!=0)\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:43:07.594635Z",
     "iopub.status.busy": "2025-04-01T13:43:07.594309Z",
     "iopub.status.idle": "2025-04-01T13:43:07.599321Z",
     "shell.execute_reply": "2025-04-01T13:43:07.598004Z",
     "shell.execute_reply.started": "2025-04-01T13:43:07.594611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def indices_por_batch(df, batch, index):\n",
    "    indices = df[index*batch:(index+1)*batch]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:48:02.948780Z",
     "iopub.status.busy": "2025-04-01T13:48:02.948437Z",
     "iopub.status.idle": "2025-04-01T13:48:03.213863Z",
     "shell.execute_reply": "2025-04-01T13:48:03.212847Z",
     "shell.execute_reply.started": "2025-04-01T13:48:02.948757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def obter_img_resize(df, batch, index, caminho = \"/kaggle/input/shopee-product-matching/train_images/\"):\n",
    "    df_parcial = indices_por_batch(df, batch, index) \n",
    "    \n",
    "    tamanho = len(df_parcial)\n",
    "    matriz = np.zeros((tamanho, 256, 256, 3),dtype='float32')\n",
    "\n",
    "    for i,(index,row) in enumerate(df_parcial.iterrows()):\n",
    "        img = cv2.imread(caminho+row.image)\n",
    "        matriz[i,] = cv2.resize(img,(256, 256)) \n",
    "\n",
    "    #matriz = matriz / 255 #normalizar imagem\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:43:19.411683Z",
     "iopub.status.busy": "2025-04-01T13:43:19.411350Z",
     "iopub.status.idle": "2025-04-01T13:43:19.418139Z",
     "shell.execute_reply": "2025-04-01T13:43:19.416626Z",
     "shell.execute_reply.started": "2025-04-01T13:43:19.411657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re #replace\n",
    " \n",
    "def removePunctuation(text):\n",
    "    punc_translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    return text.translate(punc_translator)\n",
    "\n",
    "def removeMedidas(text):\n",
    "    return re.sub(r'kg|cm|gr|ml|xl', \"\", text)\n",
    "\n",
    "\n",
    "def removeNumer(text):\n",
    "    return re.sub(r\"^[\\d\\s]+|[\\d][.\\d]+|[\\d]\", \"\", text)\n",
    "\n",
    "def removeSpecialCaracter(text):\n",
    "    return re.sub(r\"^[@.,\\\\\\/\\+\\-\\|\\[\\]]!+()\", \"\", text)\n",
    "\n",
    "def removeSpace(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:43:22.130902Z",
     "iopub.status.busy": "2025-04-01T13:43:22.130549Z",
     "iopub.status.idle": "2025-04-01T13:43:22.136057Z",
     "shell.execute_reply": "2025-04-01T13:43:22.134943Z",
     "shell.execute_reply.started": "2025-04-01T13:43:22.130875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:43:23.488428Z",
     "iopub.status.busy": "2025-04-01T13:43:23.488052Z",
     "iopub.status.idle": "2025-04-01T13:43:23.493371Z",
     "shell.execute_reply": "2025-04-01T13:43:23.492100Z",
     "shell.execute_reply.started": "2025-04-01T13:43:23.488391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def formato_submissao(row):\n",
    "    x = np.concatenate([row['predicao_efc'], row['predicao_tfidf'], row['predicao_hash']])\n",
    "    return ' '.join( np.unique(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação através das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesos do modelo baixado do link: <https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquivo importado no ambiente kaggle como modelo keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:43:26.898369Z",
     "iopub.status.busy": "2025-04-01T13:43:26.897960Z",
     "iopub.status.idle": "2025-04-01T13:43:28.860068Z",
     "shell.execute_reply": "2025-04-01T13:43:28.859032Z",
     "shell.execute_reply.started": "2025-04-01T13:43:26.898339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = EfficientNetB0(include_top=False,\n",
    "    weights='/kaggle/input/efcb0notop/keras/default/1/efficientnetb0_notop.h5',\n",
    "    input_shape=(256,256,3),\n",
    "    pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:48:06.400282Z",
     "iopub.status.busy": "2025-04-01T13:48:06.399952Z",
     "iopub.status.idle": "2025-04-01T13:49:09.107686Z",
     "shell.execute_reply": "2025-04-01T13:49:09.106575Z",
     "shell.execute_reply.started": "2025-04-01T13:48:06.400257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "BATCH = 1500\n",
    "quantidade = quant_batch(train, BATCH)\n",
    "embeds = []\n",
    "# obter embedding de forma parcial por questões de memória\n",
    "for i in range(quantidade):\n",
    "    imagens_array = obter_img_resize(train, BATCH, i)\n",
    "    image_embeddings = model.predict(imagens_array)\n",
    "    embeds.append(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_embeddings = np.concatenate(embeds) # colocar tudo em um array, ao realizar processo por batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por distância (KNN) entre embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:49:53.322771Z",
     "iopub.status.busy": "2025-04-01T13:49:53.322433Z",
     "iopub.status.idle": "2025-04-01T13:49:53.331372Z",
     "shell.execute_reply": "2025-04-01T13:49:53.330142Z",
     "shell.execute_reply.started": "2025-04-01T13:49:53.322739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighModel = NearestNeighbors(n_neighbors=50)\n",
    "neighModel.fit(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.96529770e+00, -1.31772995e-01, -1.66103140e-01, ...,\n",
       "         3.77804011e-01,  1.52934805e-01,  4.25890237e-01],\n",
       "       [-1.58917367e-01, -1.61368757e-01, -3.90131287e-02, ...,\n",
       "        -7.50639886e-02, -1.05371304e-01,  1.02647436e+00],\n",
       "       [ 1.27433017e-02, -1.14663169e-01, -1.53293550e-01, ...,\n",
       "        -2.64564529e-04, -5.29838279e-02,  7.12360859e-01]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicao = []\n",
    "CHUNK = 1500\n",
    "THRESHOLD = 4.5\n",
    "\n",
    "CTS = len(image_embeddings)//CHUNK\n",
    "if len(image_embeddings)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(image_embeddings))\n",
    "    distances, indices = neighModel.kneighbors(image_embeddings[a:b,])\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(distances[k,]< THRESHOLD)[0]\n",
    "        IDS = indices[k,IDX]\n",
    "        filtrar_vizinhos = train.iloc[IDS].posting_id.values\n",
    "        predicao.append(filtrar_vizinhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:50:28.368622Z",
     "iopub.status.busy": "2025-04-01T13:50:28.368290Z",
     "iopub.status.idle": "2025-04-01T13:50:28.384088Z",
     "shell.execute_reply": "2025-04-01T13:50:28.382726Z",
     "shell.execute_reply.started": "2025-04-01T13:50:28.368597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>target</th>\n",
       "      <th>predicao_efc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>[train_129225211]</td>\n",
       "      <td>[train_129225211]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>[train_3386243561]</td>\n",
       "      <td>[train_3386243561]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>[train_2288590299]</td>\n",
       "      <td>[train_2288590299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>[train_2406599165]</td>\n",
       "      <td>[train_2406599165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>[train_3369186413]</td>\n",
       "      <td>[train_3369186413]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret    249114794   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069   \n",
       "\n",
       "               target        predicao_efc  \n",
       "0   [train_129225211]   [train_129225211]  \n",
       "1  [train_3386243561]  [train_3386243561]  \n",
       "2  [train_2288590299]  [train_2288590299]  \n",
       "3  [train_2406599165]  [train_2406599165]  \n",
       "4  [train_3369186413]  [train_3369186413]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['predicao_efc'] = predicao\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predição feita através da distância entre vetores das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Limpeza de texto\n",
    "\n",
    "train['title_clean'] = train['title'].str.lower()\n",
    "train['title_clean'] = train['title_clean'].apply(removePunctuation)\n",
    "train['title_clean'] = train['title_clean'].map(removeMedidas)\n",
    "train['title_clean'] = train['title_clean'].apply(removeNumer)\n",
    "train['title_clean'] = train['title_clean'].apply(removeSpecialCaracter)\n",
    "train['title_clean'] = train['title_clean'].apply(removeNumer)\n",
    "train['title_clean'] = train['title_clean'].apply(removeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', \n",
    "                            binary=True, \n",
    "                            max_features=50000)\n",
    "text_embeddings = tfidf_vec.fit_transform(train.title_clean).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação de distância por lote por causa da memória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicao_idf = []\n",
    "CHUNK = 3500\n",
    "\n",
    "\n",
    "CTS = len(train)//CHUNK\n",
    "if len(train)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(train))\n",
    "    \n",
    "    # COSINE SIMILARITY DISTANCE\n",
    "    cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(cts[k,]>0.7)[0]\n",
    "        filtrar_vizinhos = train.iloc[IDX].posting_id.values\n",
    "        predicao_idf.append(filtrar_vizinhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# adição ao df\n",
    "train['predicao_tfidf'] = predicao_idf\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem imagens com o mesmo hash na coluna image_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
    "train['predicao_hash'] = train.image_phash.map(tmp)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"tfidf\", train.apply(getMetric('predicao_tfidf'),axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"hash\", train.apply(getMetric('predicao_hash'),axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:50:36.120872Z",
     "iopub.status.busy": "2025-04-01T13:50:36.120408Z",
     "iopub.status.idle": "2025-04-01T13:50:36.177651Z",
     "shell.execute_reply": "2025-04-01T13:50:36.176452Z",
     "shell.execute_reply.started": "2025-04-01T13:50:36.120820Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efc 0.9713714285714287\n"
     ]
    }
   ],
   "source": [
    "print(\"efc\", train.apply(getMetric('predicao_efc'),axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar classificação no dado de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T13:51:04.303178Z",
     "iopub.status.busy": "2025-04-01T13:51:04.302683Z",
     "iopub.status.idle": "2025-04-01T13:51:04.317596Z",
     "shell.execute_reply": "2025-04-01T13:51:04.315698Z",
     "shell.execute_reply.started": "2025-04-01T13:51:04.303144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação através das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a comparação é feita através das distâncias, os dados de treinamento não impactam, são utilizados apenas como referência da eficácia da técnica, pois o foco não é encontrar o label_group ou adaptar o modelo para identificar os rótulos. O foco é encontrar semelhança na distância entre os embeddings gerados pela imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:14:52.938377Z",
     "iopub.status.busy": "2025-04-01T14:14:52.938020Z",
     "iopub.status.idle": "2025-04-01T14:14:53.356140Z",
     "shell.execute_reply": "2025-04-01T14:14:53.354978Z",
     "shell.execute_reply.started": "2025-04-01T14:14:52.938352Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n"
     ]
    }
   ],
   "source": [
    "quantidade = quant_batch(test, BATCH)\n",
    "embeds = []\n",
    "\n",
    "for i in range(quantidade):\n",
    "    imagens_array = obter_img_resize(test, BATCH, i, \"/kaggle/input/shopee-product-matching/test_images/\")\n",
    "    image_embeddings = model.predict(imagens_array)\n",
    "    embeds.append(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:14:54.763307Z",
     "iopub.status.busy": "2025-04-01T14:14:54.762957Z",
     "iopub.status.idle": "2025-04-01T14:14:54.768056Z",
     "shell.execute_reply": "2025-04-01T14:14:54.766600Z",
     "shell.execute_reply.started": "2025-04-01T14:14:54.763281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if(quantidade>1):\n",
    "    image_embeddings = np.concatenate(embeds) # colocar tudo em um array, ao realizar processo por batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:14:59.293823Z",
     "iopub.status.busy": "2025-04-01T14:14:59.293433Z",
     "iopub.status.idle": "2025-04-01T14:14:59.301843Z",
     "shell.execute_reply": "2025-04-01T14:14:59.300852Z",
     "shell.execute_reply.started": "2025-04-01T14:14:59.293772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(len(test)<50):\n",
    "    n = len(test)\n",
    "else:\n",
    "    n = 50\n",
    "\n",
    "neighModel = NearestNeighbors(n_neighbors=n)\n",
    "neighModel.fit(image_embeddings)  #modelo feito pelo próprio dado de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:15:01.184416Z",
     "iopub.status.busy": "2025-04-01T14:15:01.184064Z",
     "iopub.status.idle": "2025-04-01T14:15:01.200641Z",
     "shell.execute_reply": "2025-04-01T14:15:01.199737Z",
     "shell.execute_reply.started": "2025-04-01T14:15:01.184389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicao = []\n",
    "CHUNK = 1500\n",
    "\n",
    "CTS = len(image_embeddings)//CHUNK\n",
    "if len(image_embeddings)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(image_embeddings))\n",
    "    distances, indices = neighModel.kneighbors(image_embeddings[a:b,])\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(distances[k,]< THRESHOLD)[0]\n",
    "        IDS = indices[k,IDX]\n",
    "        filtrar_vizinhos = test.iloc[IDS].posting_id.values\n",
    "        predicao.append(filtrar_vizinhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:15:04.517681Z",
     "iopub.status.busy": "2025-04-01T14:15:04.517347Z",
     "iopub.status.idle": "2025-04-01T14:15:04.530200Z",
     "shell.execute_reply": "2025-04-01T14:15:04.529167Z",
     "shell.execute_reply.started": "2025-04-01T14:15:04.517654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>predicao_efc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title       predicao_efc  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  [test_2255846744]  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  [test_3588702337]  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  [test_4015706929]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicao_efc'] = predicao\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#pré-processamento para tfidf\n",
    "test['title_clean'] = test['title'].str.lower()\n",
    "test['title_clean'] = test['title_clean'].apply(removePunctuation)\n",
    "test['title_clean'] = test['title_clean'].map(removeMedidas)\n",
    "test['title_clean'] = test['title_clean'].apply(removeNumer)\n",
    "test['title_clean'] = test['title_clean'].apply(removeSpecialCaracter)\n",
    "test['title_clean'] = test['title_clean'].apply(removeNumer)\n",
    "test['title_clean'] = test['title_clean'].apply(removeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "text_embeddings = tfidf_vec.transform(test.title_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicao_idf = []\n",
    "CHUNK = 3500\n",
    "\n",
    "\n",
    "CTS = len(test)//CHUNK\n",
    "if len(test)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(test))\n",
    "    \n",
    "    # COSINE SIMILARITY DISTANCE\n",
    "    cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(cts[k,]>0.7)[0]\n",
    "        filtrar_vizinhos = test.iloc[IDX].posting_id.values\n",
    "        predicao_idf.append(filtrar_vizinhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# adição ao df\n",
    "test['predicao_tfidf'] = predicao_idf\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# classificação por hash\n",
    "tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
    "test['predicao_hash'] = test.image_phash.map(tmp)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação para arquivo de envio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse tipo de competição, necessário importar o arquivo de teste e gerar o arquivo de submissão com as previsões no próprio código. Durante a submissão, o arquivo de teste é substituído com o verdadeiro conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test['matches'] = test.apply(formato_submissao, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/kaggle/input/shopee-product-matching/sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = test[['posting_id','matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T14:59:57.750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample.to_csv(f'/kaggle/working/submission.csv',mode='a',index=False,header=True)\n",
    "\n",
    "sub = pd.read_csv('submission.csv')\n",
    "sub.head(6)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1878097,
     "isSourceIdPinned": false,
     "sourceId": 24286,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 285040,
     "modelInstanceId": 263943,
     "sourceId": 311211,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
